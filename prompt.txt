「宿題の写真を撮る→discordのbotに送る→VLMやOCRやLLMを介して解説を作成（処理方法は添付画像参考）→処理には時間がかかるので、先に解説文は生成しておく→disocrdで準備完了などと送る→VRヘッドセット(quest)をつける→webカメラで手元を移す→手元の紙で「おしえて！」とかく(pyでそれを認識する)→vr内で、先生役の妹が黒板にスライドを乗せて勉強を教えてくれる→その後解いてって、わからない問題があれば"Pkaisetu"と書いて、その一番近くの問題を解説する」というプロジェクトの、unity以外の部分(AIの部分)のpythonコードを書いて。

 「vrアプリが入ってるquestのポート12346」に画像を送信すると、その画像がunity内に表示されるのでそこに投げて。その投げられた画像はVR内の黒板に映し出されます（この黒板は既に実装済みです。また、この黒板は上書き式で新しい画像が送信されると新しいものが表示されます）。途中でスライド作成のpyを書いてもらうフェーズがありますが、そのpyは自動で実行してスライドを作成してもらって(名前やライブラリなどはプロンプトで指定してエラーを避けて)。スライドが何枚かあると適切に表示されないので、「１枚だけにして」とプロンプトでいったり、レイアウトを変更したり、スライドを随時更新したり(この場合はタイミングに注意)して。 webカメラは常時手元を移しているので、「Pkaisetu」と書かれたことを認識したら写真を撮って、「その"Pkaisetu"の近くにある問題」の解き方をより詳しく教えてあげて。途中式が書かれている場合もあるのでその時はそれも含めて読み取って「〜まで合ってるよ！」とか「〜から間違っているよ！」とかを伝えるようにして。 "Pkaisetu"を何回も認識したり、過去の"Pkaisetu"を認識しないようにしたりしてバグ対策もして（「わかった！考えるから"Pkaisetu"を消して待っててね～」と言って処理が終わるまでPkaisetuを認識しない等）。もし"Pkaisetu"の近くの問題の、ユーザーの回答が正解していたら褒めて。他にも「リスタート」と書いて解説を初めからやる等、何個かコマンドを考えて(学習用のプリントに含まれてたりする単語はバグにつながるので使用しないで)。また、voicevoxを介して読み上げもしてほしいので、それの機能もつけて、読み上げ用のunity側のcsも書いて。 voicevoxはローカルで起動しています。  また、各LLM(nougatやyomitokuはライブラリのため除く)はLMstudioに読み込まれています。日本語が不得意なLLMも含まれるので、その時はプロンプトは英語で書いて。パス指定とvrのip指定がしやすいようにコードは書いて、コメントはできるだけ書かないで。 画像のような処理構造にして、とても良い感じの性能になるようにして。なので、「内部処理用のpyと、それを使うためのunity用のcs(先生のモデルに紐づけます)」を書いて。「処理の重複(追い抜きや上書き)や、ユーザーの意図しないタイミングでの解説、その他ユーザー体験が損なわれる不自然な挙動」を防ぐためのその他の対策はあなたが少なくとも10個以上は考えて実装して。生成時のメモやなどは./tmpディレクトリに適当に保存して。###unityへの画像の送信例： result, encoded_img = cv2.imencode('.jpg', frame, encode_param) data = encoded_img.tobytes() sock.sendto(data, (UDP_IP, UDP_PORT))### - ###LMStudioへのポスト例(VLM)：def send_image_prompt_to_lmstudio():     # 画像をbase64エンコード     with open("./image.png", "rb") as image_file:         image_data = base64.b64encode(image_file.read()).decode('utf-8')          # リクエストデータ     data = {         "model": "gemma-3-12b-it",         "messages": [             {                 "role": "system",                 "content": "You are a helpful assistant that can analyze images."             },             {                 "role": "user",                 "content": [                     {                         "type": "text",                         "text": "この画像について説明してください。"                     },                     {                         "type": "image_url",                         "image_url": {                             "url": f"data:image/png;base64,{image_data}"                         }                     }                 ]             }         ],         "temperature": 0.7,         "max_tokens": -1,         "stream": False     }          # LMStudioへリクエスト送信     response = requests.post(         "http://rinnas.f5.si:1234/v1/chat/completions",         headers={"Content-Type": "application/json"},         json=data     )          # レスポンス表示     if response.status_code == 200:         result = response.json()         print(result["choices"][0]["message"]["content"])     else:         print(f"Error: {response.status_code}")         print(response.text)  if __name__ == "__main__":     send_image_prompt_to_lmstudio()